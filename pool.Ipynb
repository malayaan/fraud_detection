{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data from the differente folders\n",
    "\n",
    "# Transaction Records\n",
    "transaction_records = pd.read_csv('Folder1/transaction_records.csv')\n",
    "\n",
    "# Transaction Metadata\n",
    "transaction_metadata = pd.read_csv('Folder1/transaction_metadata.csv')\n",
    "\n",
    "# Customer Data\n",
    "customer_data = pd.read_csv('Folder2/customer_data.csv')\n",
    "\n",
    "# Account Activity\n",
    "account_activity = pd.read_csv('Folder2/account_activity.csv')\n",
    "\n",
    "# Suspicious Activity\n",
    "suspicious_activity = pd.read_csv('Folder3/suspicious_activity.csv')\n",
    "\n",
    "# Amount Data\n",
    "amount_data = pd.read_csv('Folder4/amount_data.csv')\n",
    "\n",
    "# Anomaly Scores\n",
    "anomaly_scores = pd.read_csv('Folder4/anomaly_scores.csv')\n",
    "\n",
    "# Merchant Data\n",
    "merchant_data = pd.read_csv('Folder5/merchant_data.csv')\n",
    "\n",
    "# Transaction Category Labels\n",
    "transaction_category_labels = pd.read_csv('Folder5/transaction_category_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the distribution of the discrete data \n",
    "\n",
    "# We should use countplot for SuspiciousFlag feature\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Adjust the figure size if needed\n",
    "sns.countplot(x='SuspiciousFlag', data=data, palette='Set2')  # You can change the palette as desired\n",
    "plt.title('Count Plot for Suspicious Flag')\n",
    "plt.xlabel('Suspicious Flag')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels if they are long\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting TimeStamp to datetime format\n",
    "\n",
    "data_cleaned['Timestamp1'] = pd.to_datetime(data_cleaned['Timestamp'])\n",
    "\n",
    "print(data_cleaned.dtypes)\n",
    "\n",
    "data_cleaned['Hour'] = data_cleaned['Timestamp1'].dt.hour\n",
    "data_cleaned['LastLogin'] = pd.to_datetime(data_cleaned['LastLogin'])\n",
    "data_cleaned['gap'] = (data_cleaned['Timestamp1'] - data_cleaned['LastLogin']).dt.days.abs()\n",
    "\n",
    "data_cleaned = data_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete duplicates\n",
    "\n",
    "print(\"numbers of rows before duplicates removal :\", data.shape[0])\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "print(\"numbers of rows after duplicates removals :\", data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul of the mean of the target variable for each category: mean encoding\n",
    "merchant_means = X_train.groupby('MerchantID')['FraudIndicator'].mean()\n",
    "category_means = X_train.groupby('Category')['FraudIndicator'].mean()\n",
    "customer_means = X_train.groupby('CustomerID')['FraudIndicator'].mean()\n",
    "\n",
    "# Application of the mapping\n",
    "X_train['MerchantID'] = X_train['MerchantID'].map(merchant_means)\n",
    "X_train['Category'] = X_train['Category'].map(category_means)\n",
    "X_train['CustomerID'] = X_train['CustomerID'].map(customer_means)\n",
    "\n",
    "X_test['MerchantID'] = X_test['MerchantID'].map(merchant_means)\n",
    "X_test['Category'] = X_test['Category'].map(category_means)\n",
    "X_test['CustomerID'] = X_test['CustomerID'].map(customer_means)\n",
    "\n",
    "X_train['MerchantID'].fillna(0, inplace=True)\n",
    "X_train['Category'].fillna(0, inplace=True)\n",
    "X_train['CustomerID'].fillna(0, inplace=True)\n",
    "\n",
    "X_test['MerchantID'].fillna(0, inplace=True)\n",
    "X_test['Category'].fillna(0, inplace=True)\n",
    "X_test['CustomerID'].fillna(0, inplace=True)\n",
    "\n",
    "X_train = X_train.drop(['FraudIndicator'], axis=1)\n",
    "X_test = X_test.drop(['FraudIndicator'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data exploration:\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('path/to/your/file.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First rows of the DataFrame:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display the columns of the DataFrame\n",
    "print(\"\\nColumns of the DataFrame:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(\"\\nSize of the DataFrame:\")\n",
    "print(data.shape)\n",
    "\n",
    "# Display information about the DataFrame\n",
    "print(\"\\nInformation about the DataFrame:\")\n",
    "print(data.info())\n",
    "\n",
    "# Count missing values in each column\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nNumber of duplicates:\")\n",
    "print(data.duplicated().sum())\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types in the DataFrame:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Count unique values in each column\n",
    "print(\"\\nNumber of unique values in each column:\")\n",
    "print(data.nunique())\n",
    "\n",
    "# Unique values in a specific column (replace 'ColumnName' with the actual column name)\n",
    "print(\"\\nUnique values in a specific column:\")\n",
    "print(data['ColumnName'].unique())\n",
    "\n",
    "# Distribution of categorical values (replace 'ColumnName' with the actual column name)\n",
    "print(\"\\nDistribution of values in a categorical column:\")\n",
    "print(data['ColumnName'].value_counts())\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = data.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"\\nNumerical features:\")\n",
    "print(numerical_features)\n",
    "print(\"\\nCategorical features:\")\n",
    "print(categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets divide the data into two parts: one for training and the other for testing\n",
    "\n",
    "# select the features and the target\n",
    "features = data_cleaned.drop(['Timestamp', 'Timestamp1', 'LastLogin', 'Address'], axis=1)\n",
    "target = pd.read_csv(\"label.csv\")\n",
    "\n",
    "features['FraudIndicator'] = target\n",
    "\n",
    "\n",
    "# Divide the data into training and testing sets: 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general importation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings as wr\n",
    "wr.filterwarnings(action=\"ignore\")\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot duplicates and missing values\n",
    "duplicates = data.duplicated(keep=False)  # 'keep=False' flag all duplicates as True\n",
    "print(\"duplicats detected:\")\n",
    "print(data[duplicates])\n",
    "\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nmissing values by columns:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets delete the rows with missing values\n",
    "\n",
    "print(\"number of row before missing values removal :\", data.shape[0])\n",
    "\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "# Afficher le nombre de lignes après la suppression des données manquantes\n",
    "print(\"number of row after missing values removal :\", data_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsuful columns deletion\n",
    "\n",
    "print(\"DataFrame before the columns deletion :\")\n",
    "print(data.head())\n",
    "\n",
    "columns_to_drop = ['TransactionID', 'Name']\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"\\nDataFrame after the columns deletion : :\")\n",
    "print(data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot somme graphs to see the distribution of the data\n",
    "\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':  # Check if the column has a categorical data type\n",
    "        top_10_values = data[column].value_counts().head(10)  # Get the first 10 unique values and their counts\n",
    "        plt.figure(figsize=(10, 5))  # Adjust the figure size if needed\n",
    "        sns.countplot(x=column, data=data, order=top_10_values.index)\n",
    "        plt.title(f'Count Plot for {column}')\n",
    "        plt.xticks(rotation=90)  # Rotate x-axis labels if they are long\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion of transaction data\n",
    "transaction_data = pd.merge(transaction_records,amount_data, on=\"TransactionID\")\n",
    "transaction_data = pd.merge(transaction_data, transaction_metadata, on=\"TransactionID\")\n",
    "transaction_data = pd.merge(transaction_data, anomaly_scores, on=\"TransactionID\")\n",
    "transaction_data = pd.merge(transaction_data, transaction_category_labels, on=\"TransactionID\")\n",
    "\n",
    "# fusion of customer data\n",
    "customer_data = pd.merge(customer_data, account_activity, on=\"CustomerID\")\n",
    "customer_data = pd.merge(customer_data, suspicious_activity, on=\"CustomerID\")\n",
    "\n",
    "# final fusion between transaction data and customer data\n",
    "data = pd.merge(transaction_data, customer_data, on=\"CustomerID\")\n",
    "\n",
    "# lets print the first lines of the combined data\n",
    "print(\"Combined Data:\")\n",
    "print(data.head())\n",
    "print(\"\\nTransaction Data:\")\n",
    "print(transaction_data.head())\n",
    "print(\"\\nCustomer Data:\")\n",
    "print(customer_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first lines of each dataset for review\n",
    "\n",
    "print(\"Transaction Records:\")\n",
    "print(transaction_records.head())\n",
    "\n",
    "print(\"\\nTransaction Metadata:\")\n",
    "print(transaction_metadata.head())\n",
    "\n",
    "print(\"\\nCustomer Data:\")\n",
    "print(customer_data.head())\n",
    "\n",
    "print(\"\\nAccount Activity:\")\n",
    "print(account_activity.head())\n",
    "\n",
    "print(\"\\nSuspicious Activity:\")\n",
    "print(suspicious_activity.head())\n",
    "\n",
    "print(\"\\nAmount Data:\")\n",
    "print(amount_data.head())\n",
    "\n",
    "print(\"\\nAnomaly Scores:\")\n",
    "print(anomaly_scores.head())\n",
    "\n",
    "print(\"\\nMerchant data_cleaned_cleaned:\")\n",
    "print(merchant_data.head())\n",
    "\n",
    "print(\"\\nTransaction Category Labels:\")\n",
    "print(transaction_category_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the distribution of the numerical data\n",
    "\n",
    "# Get the number of numerical columns\n",
    "num_cols = len(data.select_dtypes(include=['number']).columns)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = (num_cols // 2) + (num_cols % 2)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(12, 6*num_rows))\n",
    "fig.suptitle(\"Box Plots for Numerical Columns\")\n",
    "\n",
    "# Loop through the numerical columns and create box plots\n",
    "for i, column in enumerate(data.select_dtypes(include=['number']).columns):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    sns.boxplot(x=data[column], ax=axes[row, col])\n",
    "    axes[row, col].set_title(column)\n",
    "\n",
    "# Remove any empty subplots\n",
    "if num_cols % 2 != 0:\n",
    "    fig.delaxes(axes[num_rows-1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)  # Adjust the position of the overall title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the correlation matrix\n",
    "\n",
    "# Select only the numeric columns\n",
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate the correlation matrix for numeric columns\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap for Numeric Columns')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age completion\n",
    "age_median = data['Age'].median()\n",
    "data['Age'].fillna(age_median, inplace=True)\n",
    "\n",
    "# address completion\n",
    "most_common_address = data['Address'].mode()[0]\n",
    "data['Address'].fillna(most_common_address, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
